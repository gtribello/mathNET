<PAGE>
  <TITLE> Stochastic Processes and Risk </TITLE>
  <DESCRIPTION>
     The theory of stochastic process is used to model the future behavior of systems in fields ranging from finance to weather forecasing. 
     In stochastic models the future behavior of the system is modelled using random variables and probability.  One can thus obtain information
     on the likelihood that the future will transpire in a particular way.
     
     In this module we focus primarily on probabilistic models that have the Markov property.  In these models the probability of the future transpiring in a 
     particular way depends only on the present state of the system and not on what happened in the past. These models find application in physics, quantitative
     finance and machine learning.  A particularly important application of Markov processes is the method of Monte Carlo integration.  We will thus finish by 
     studying this technique and its application to problems in Bayesian inference.
  </DESCRIPTION> 
  <AIMS>
     <UL> 
       <LI> You should be able to calculate expectations and variances directly, using the moment generating function and by using the conditional expectation theorem.  You should also be able to explain what predictions can be made given the expectation and/or the variance. </LI>
       <LI> You should be able to recognise which type of random variable is appropriate for modelling a given phenomenon, identify the assumptions that they have made in constructing this model and critically assess their validity.â€¨</LI>
       <LI> You should be able to explain what it means when we state that a time dependent process has independent and stationary increments and how this differs from a Markov process.  By using your understanding of this distinction you should be able to construct probabilistic models for time dependent phenomena, explain the assumptions that have been made in the constructing these models and critically assess their validity. </LI>
     </UL>
  </AIMS>
  <CHAPTER>
     <TITLE> Random variables </TITLE>
     <INTRO>
        <DESCRIPTION> 
           The first project in the course is all about revisiting the material on random variables and probability theory that you learnt in the level one course.  During this part of the course you 
           will learn about uniform, bernoulli, binomial, poisson, geometric and normal random variables.  You will revise important concepts in probability theory and statistics such as expectation,
           variance, independence, cumulative probability distribution functions, probability density functions and probability mass fuctions.  You will also be introduced to the moment generating 
           function.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to explain how the cumulative probability distribution function and the probabiltiy mass/density function are related. </LI>
              <LI> You should be able to write out the probability mass functions for the bernoulli, binomial, poisson and geometric rando variables.  You should be able to write out the probability density functions for the uniform and normal random variables. </LI>
              <LI> You should be able to calculate expectations and variances directly, using the moment generating function and by using the conditional expectation theorem. </LI>
              <LI> You should be able to write programs to generate uniform, bernoulli, binomial, poisson, geometric and normal random variables. </LI>
           </UL>
        </AIMS> 
     </INTRO>
     <PROJECT>
        <TITLE> Investigating other random variables </TITLE>
        <DESCRIPTION>
           Performing the exercises in the apply and extend parts of this project will teach you how to generate uniform, bernoulli, binomial, poisson, geometric and normal random variables.
           You will learn how to derive expressions for the expectations and variances of these different types of random variables from the random variables parameters.  Furthermore, you 
           will learn about the law of large numbers and how we can estimate expectations and probability distribution functions by repeatedly generating random variables from a particular 
           distribution.  The final exercises listed below take these ideas a little further.  You will need to research these topics online and you may also want to discuss them with your 
           lecturer.

           <UL>
              <LI> As part of your project on random variables you wrote a program to estimate the probability mass/density function for a particular random variable that worked by generating a large number of identically distributed random variables.  Now write a program to estimate the cumulative probability distribution function for the same kind of random variable you wrote your project on. </LI> 
              <LI> Suppose that $X$ is a geometric random variable with $p=0.5$.  Now suppose that we generate a random variable $Z$ that is a function of $X$ using $Z = 2^X$.  Write a python notebook that generates multiple instances of this random variable $\{ Z_i \}$.  Draw a graph that shows how the sample mean, $\mu_n = \frac{1}{N} \sum_{i=1}^n Z_i$, changes as the number of variables it is calculated from increases.  Discuss the behaviour of this sample mean and compare it to the behaviour that you observed for the other random variables you have investigated.  Derive an expression for the expression for the expectation of this random variable and use this expression to explain why the sample mean for this random variable behaves in the way you observe. </LI> 
              <LI> Write a program that generates random variables from a Cauchy distribution.  Generate a large number of identically distributed Cauchy random variables and use this data to estimate the probability density function for your random variable.  </LI>
              <LI> Discuss how Student's-t-distribution arises from sampling and how this distribution differs from the standard normal distribution.  You should write a program that generates random variable from Student's-t-distribution and make sure that you plot the a graph of showing how the shape of the $t$ distribution changes as the number of degrees of freedom is increased. </LI>
           </UL>
        </DESCRIPTION>
     </PROJECT>
     <TOPIC> RANDOM_VARIABLES </TOPIC>
     <TOPIC> BERNOULI_RANDOM_VARIABLE </TOPIC>
     <TOPIC> BINOMIAL_RANDOM_VARIABLE </TOPIC>
     <TOPIC> GEOMETRIC_RANDOM_VARIABLE </TOPIC>
     <TOPIC> POISSON_RANDOM_VARIABLE </TOPIC>
     <TOPIC> UNIFORM_RANDOM_VARIABLE </TOPIC>
     <TOPIC> NORMAL_RANDOM_VARIABLE </TOPIC>
     <TOPIC> EXPECTATION </TOPIC>
     <TOPIC> VARIANCE </TOPIC>
     <TOPIC> MOMENT_GENERATING_FUNCTION </TOPIC>
     <TOPIC> LAW_OF_LARGE_NUMBERS </TOPIC>
  </CHAPTER>
  <CHAPTER>
     <TITLE> The central limit theorem </TITLE>
     <INTRO>
        <DESCRIPTION>
           The second project in the course is all about the central limit theorem, which is arguably the central theorem in statistics.  Once again you learnt about this theorem in level one but this 
           material is difficult so it bears repeating.  The central idea idea that we are trying to get at with this part of the course concerns using probability theory to develop a numerical measure 
           for the degree of confidence that we have in a particular (quantitative) statement.  The simple version of this idea is that if we have two measurements of some quantity that are very similar 
           we are more likely to believe that each of the individual measurements represent something close to the truth.  We are mathematicians though so we would like to develop a more quantitative version 
           of this intuition.  This is what the central limit theorem allows us to do.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to explain the difference between systematic and random error. </LI> 
              <LI> You should be able to state the central limit theorem and define all the terms in this theorem correctly. </LI>
              <LI> You should be able to calculate confidence limits that give a measure of the random error in the sample mean calculated from a set of indepdendent random variables. </LI>
           </UL>
        </AIMS>
     </INTRO>
     <PROJECT>
        <TITLE> Understanding fractals with random variables </TITLE>
        <DESCRIPTION>
           <table>
           <tr> <td> 
           The figure on the left of this slide shows an image of the Mandelbrot set.  This set contains all the complex numbers, $c$, for which the orbit of 0 under 
           iteration of the quadratic map:
           $$
           z_{n+1} = z_n + c
           $$ 
           remains bounded.  The python script below gives a method for calculating the area of the Mandelbrot set.  Discuss how this code works and try to extend it 
           so that is also outputs confidence limits on the estimate of the area.  Then try and see if you can write a piece of software to esimtate the fractal 
           dimension of the Mandelbrot set.
           </td> <td> <img src="Images/1280px-Mandel_zoom_00_mandelbrot_set.jpg"/> </td> </tr> 
           </table>
           <br/>
           <div class=" highlight hl-ipython3"><pre><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">cmath</span>

<span class="n">npoints</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">maxiter</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">noutside</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">npoints</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">trialp</span> <span class="o">=</span> <span class="nb">complex</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span> <span class="o">+</span> <span class="mf">2.5</span><span class="o">*</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="mf">1.125</span><span class="o">*</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">zn1</span> <span class="o">=</span> <span class="n">trialp</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">maxiter</span><span class="p">)</span> <span class="p">:</span>
        <span class="n">zn1</span> <span class="o">=</span> <span class="n">zn1</span><span class="o">*</span><span class="n">zn1</span> <span class="o">+</span> <span class="n">trialp</span>
        <span class="n">r</span><span class="p">,</span> <span class="n">thet</span> <span class="o">=</span> <span class="n">cmath</span><span class="o">.</span><span class="n">polar</span><span class="p">(</span><span class="n">zn1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="p">:</span>
            <span class="n">noutside</span> <span class="o">=</span> <span class="n">noutside</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="k">break</span>

<span class="n">ninside</span> <span class="o">=</span> <span class="n">npoints</span> <span class="o">-</span> <span class="n">noutside</span>
<span class="n">area</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="mf">2.5</span><span class="o">*</span><span class="mf">1.125</span><span class="p">)</span> <span class="o">*</span> <span class="n">ninside</span> <span class="o">/</span> <span class="n">npoints</span>

<span class="nb">print</span><span class="p">(</span> <span class="n">ninside</span><span class="p">,</span> <span class="n">area</span> <span class="p">)</span>
</pre></div>
        </DESCRIPTION>
     </PROJECT>
     <TOPIC> CONDITIONAL_PROBABILITY </TOPIC>
     <TOPIC> INDEPENDENT_RANDOM_VARIABLES </TOPIC>
     <TOPIC> JOINT_PROBABILITY_DISTRIBUTION </TOPIC> 
     <TOPIC> BAYES_THEOREM </TOPIC>
     <TOPIC> CONDITIONAL_EXPECTATION </TOPIC>
     <TOPIC> CENTRAL_LIMIT_THEOREM </TOPIC>
  </CHAPTER>
  <CHAPTER>
     <TITLE> Markov chains in discrete time </TITLE>
     <INTRO>
        <DESCRIPTION>
           In this third project we introduce the Markov property and thus begin our study of random, time-dependent processes.  In this part of the course we assume that we are monitoring our 
           random process at particular points in time rather than assuming we are monitoring the random process continuously.  Furthermore, we assume that the random variable whose value we 
           are monitoring in time can only take integer values.  To describe these processes we introduce the notion of a transition graph and a transition matrix.  You will learn how to write programs
           to simulate Markov chains and will learn how quantitative predictions can be made for these random processes by examining the limiting behavior of the chains.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to state what it means when we say that a time series of random variables has the Markov property </LI>
              <LI> You should be able to interpret transition graphs and transition probability matrices and you should also be able to use the Chapman-Kolmogorov relation to calculate the $n$-step transition probability matrix from the 1-step transition probability matrix. </LI>
              <LI> You should be able to discuss the limiting behavior of Markov chains.  This means you should be able to calculate limiting stationary distributions, hitting times and hitting probabilities. </LI>
              <LI> You should be able to write a computer program to simulate a random walk in one dimension. </LI>
           </UL>
        </AIMS>
     </INTRO>
     <PROJECT>
       <TITLE> Teaching with Markov chains </TITLE>
       <DESCRIPTION>
          For each of the four projects that you will perform in this course you will find a graph indicating the connectivity between the various topics that we are studying
          in those weeks if you click on menu item content.  Pick one of these graphs and write a program to simulate a discrete time Markov chain that has this particular connectivity between its states.
          Discuss whether each of the topics in the graph is transient or recurrent and whether or not the graphs have a stationary distribution.  If the chains do not have a stationary
          distributon calculate the hitting times and hitting probabilities for the adsorbing states in the chain.  Once you have done this modify the transition graph and add connections so 
          that the Markov chain does have a stationary distribution. Calculate the elements of this stationary distribution.  Discuss how graphs and Markov chains might be used to understand how 
          people learn and understand new ideas and how we can use these ideas to categorize information. 
       </DESCRIPTION>
     </PROJECT>
     <TOPIC> MARKOV_PROPERTY </TOPIC>
     <TOPIC> TRANSITION_MATRIX_OF_MARKOV_CHAIN </TOPIC>
     <TOPIC> CHAPMAN_KOLMOGOROV_RELATION </TOPIC>
     <TOPIC> TRANSIENT_RECURRENT_STATES </TOPIC>
     <TOPIC> STATIONARY_DIST_MARKOV </TOPIC>
     <TOPIC> HITTING_PROBABILITIES </TOPIC>
     <TOPIC> GAMBLERS_RUIN </TOPIC> 
  </CHAPTER>
  <CHAPTER> 
     <TITLE> Markov chains in continuous time </TITLE>
     <INTRO>
        <DESCRIPTION>
           The final part of the course takes what you have learnt about discrete time Markov chains and extends it so that it also works in continuous time.  Doing so ensures that we can model processes
           where there are discrete states and where the times between transitions between these states are random.  We can thus use the theory of Markov chains to model processes such as queues and the 
           progression of diseases.  A discussion of Markov chains in continous time also allows us to move beyond the Markovian assumption and to thus introduce more complex time-dependent random processes.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to write out and solve the Kolmogorov forward equation. </LI>
              <LI> You should be able to derive the equations of the Poisson process and you should also be able to write programs to simulate poisson processes. </LI>
              <LI> You should be able to work with Markov models that describe queues. This includes being able to  write programs to simulate queues. </LI>
              <LI> You should be able how models of random processes that relax the assumption of Markovianity can be developed. </LI>
           </UL>
        </AIMS>
     </INTRO>
     <PROJECT>
       <TITLE> Field tests for Glaucoma </TITLE>
       <DESCRIPTION>
          Glaucoma is a disease of the eyes that affects old people.  One of the symptoms of this disease is a loss of periferal vision and a narrowing of the patients 
          field of vision.  Patients who have Glaucoma thus undergo regular visual field tests in order to monitor the progress of the disease.  When a person undergoes 
          a field test their head is placed in a machine like that shown in the image on the right here with one eye blindfolded.  The patient stares at an led in the center
          of the machine, while short and sharp burst appear at various points in the remainder of the machine.  The patient must then push a button whenever s/he sees one of these
          bursts of light.

          <UL>
            <LI> Write a program that could be used to control where and when the points of light are generated inside a machine for performing field tests and how bright they are.  Explain how your program addresses the fact that people are primed to recognize regular repeating patterns in the intervals between events when there are repeated stimuli.  This is a problem for field tests as people's subconciouses might lead them to see lights that simply are not there if the timing between each light being generated is too regular. </LI>
            <LI> Write a program that is able to simulate the patients response (pressing the button) in repsonse to each of the light pulses generated by your program.  Discuss what experiments you would need to do on patients in order to determine how to set the parameters in your algorithm for generating light pulses. </LI>  
          </UL> 
       </DESCRIPTION>
     </PROJECT>
     <TOPIC> CONTINUOUS_TIME_MARKOV_CHAIN </TOPIC>
     <TOPIC> EXPONENTIAL_RANDOM_VARIABLE </TOPIC>
     <TOPIC> POISSON_PROCESS </TOPIC>
     <TOPIC> MM1_QUEUE </TOPIC>
     <TOPIC> INHOMOGENEOUS_POISSON_PROCESS </TOPIC>
     <TOPIC> COMPOUND_POISSON_PROCESS </TOPIC>
  </CHAPTER>
</PAGE>
