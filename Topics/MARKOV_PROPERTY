TITLE: The Markov Property

DESCRIPTION:

A time series of random variables, $X_1, X_2, X_3, \dots$, is said to be a Markov chain if it has the following property:
$$
P(X_t=x_t|X_0=x_0,X_1=x_1,\dots,X_{t-1}=x_{t-1}) = P(X_t=x_t|X_{t-1}=x_{t-1})
$$

LEARNINGOUTCOMES:

- You should be able to write out the definition of the Markov property.
- You should be able to explain why the Markov property ensures that we can represent a Markov chain using a transition graph.
- You should be able to interpret the elements of the transition probability matrix by making reference to the Markov property.

END:


MARKOV_PROPERTY INTRO HTML SOR3012 markov-property-video G.~Tribello Introduction to the Markov property
MARKOV_PROPERTY INTRO PDF SOR3012 jim-chap12.pdf J.~F.~McCann Introductory notes on Markov chains and the Markov property.
