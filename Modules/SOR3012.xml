<PAGE>
  <TITLE> Stochastic Processes and Risk </TITLE>
  <DESCRIPTION>
     The theory of stochastic process is used to model the future behavior of systems in fields ranging from finance to weather forecasing. 
     In stochastic models the future behavior of the system is modelled using random variables and probability.  One can thus obtain information
     on the likelihood that the future will transpire in a particular way.
     
     In this module we focus primarily on probabilistic models that have the Markov property.  In these models the probability of the future transpiring in a 
     particular way depends only on the present state of the system and not on what happened in the past. These models find application in physics, quantitative
     finance and machine learning.  A particularly important application of Markov processes is the method of Monte Carlo integration.  We will thus finish by 
     studying this technique and its application to problems in Bayesian inference.
  </DESCRIPTION> 
  <AIMS>
     <UL> 
       <LI> You should be able to calculate expectations and variances directly, using the moment generating function and by using the conditional expectation theorem.  You should also be able to explain what predictions can be made given the expectation and/or the variance. </LI>
       <LI> You should be able to recognise which type of random variable is appropriate for modelling a given phenomenon, identify the assumptions that they have made in constructing this model and critically assess their validity.
</LI>
       <LI> You should be able to explain what it means when we state that a time dependent process has independent and stationary increments and how this differs from a Markov process.  By using your understanding of this distinction you should be able to construct probabilistic models for time dependent phenomena, explain the assumptions that have been made in the constructing these models and critically assess their validity. </LI>
     </UL>
  </AIMS>
  <LITURGY>
     <ITEM>
        <CALL> How do we use capital letters in statistics? </CALL>
        <RESPONSE> In statistics we use capital letters to denote the random outcomes from experiments performed in the future. </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do we encode the information we have about what might happen in those experiments in the future mathematically?</CALL>
        <RESPONSE> 
           We encode our understanding of what might happen in those experiments in the future in a function known as the cumulative probability distribution function.  
           The value of this function, $F_X(x)$, at small x tells you the probability that the random variable will take a value less than or equal to x.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> Give three properties that all cumulative probability distribution functions must have? </CALL>
        <RESPONSE>
            The cumulative probability distribution must have the following three properties: $\lim_{x\rightarrow -\infty} P(X\le x ) = 0$,
            $\lim_{x\rightarrow +\infty} P(X\le x ) = 1$ and $\lim_{\epsilon \rightarrow 0} P(X\le (x+\epsilon) ) = P( X \le x )$
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is the difference between discrete and continuous random variables? </CALL>
        <RESPONSE> 
           Discrete random variables cannot take any real value on the real axis.  They can only take particular (usually integer) values.
           Continuous random variables can take any real value in a particular range. 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What does the probability mass function $f_X(x)$ measure? </CALL>
        <RESPONSE>
           The probability mass function $f_X(x)$ tells one the probability that the {\bf discrete} random variable (capital) $X$ will take a value of (small) $x$. 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What does the probability density function $f_X(x)$ measure? </CALL>
        <RESPONSE>
           The probability density function $f_X(x)$ is equal to the derivative of the cumulative probability distribution function for the {\bf continuous} random 
           variable (capital) $X$ evaluated at the point (small) $x$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do you calculate the expectation of a discrete random variable? </CALL>
        <RESPONSE>
           The expectation of a discrete random variable is equal to the sum over all the possible values that the random variable can take of 
           $x_i$ multiplied by the probabiltiy mass function $f_X(x_i)$.  In other words, $\mathbb{E}[X] = \sum_{i=0}^\infty x_if_X(x_i)$
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do you calculate the expectation of a continuous random variable? </CALL>
        <RESPONSE>
           The expectation of a continuous random variable is equal to the integral over all possible $x$ values of $x$ multiplied by the probability 
           density function, $f_X(x)$.  In other words, $\mathbb{E}[X] = \int_{-\infty}^{\infty} x f_X(x) \textrm{d}x$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do you calculate the variance of a random variable? </CALL>
        <RESPONSE>
           The variance of a random variable, $X$, can be calculated by taking the expectation of $[X-\mathbb{E}(X)]^2$ or by computing the expectation 
           of the square of the random variable, $\mathbb{E}(X^2)$, and by subtracting $\mathbb{E}(X)^2$. 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How is the moment generating function calculated and explain how one can calculate moments if one is given this function </CALL>
        <RESPONSE>
           The moment generating function, $M_X(t)$ for a random variable, $X$, is $M_X(t) = \mathbb{E}(e^{tX})$.  If one evaluates the $n$th derivatives 
           of this function at $t=0$ one gets the $n$th moment of the distribution
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> Why is the expectation an important quantity? </CALL>
        <RESPONSE>
           The expectation is important because the sum of $n$ independent and identically distributed random variables divided by $n$ converges towards this 
           particular value because of a result known as the law of large numbers.  The law of large number states:
           $$
           \lim_{n\rightarrow \infty} P\left( \left| \frac{S_n}{n} - \mathbb{E}(X) \right| &gt; \epsilon \right) = 0
           $$
           where $n$ is the number of independent random variables with expectation $\mathbf{E}(X)$ that have been added together to give $S_n$ and where $\epsilon$ 
           is a small number.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What does the central limit theorem state? </CALL>
        <RESPONSE>
           The central limit theorem states that the cumulative probability distribution function for a sum of independent and identically distributed random variables of 
           most types can be approximated using the cumulative probability distribution function of a normal distribution.  More precisely it states:
           $$
            \lim_{n \rightarrow \infty} P\left( \frac{S_n/n - \mu}{\sigma/\sqrt{n}} \le z \right) = \Phi(z)
           $$
           where $n$ is the number of independent random variables with expectation $\mu$ and variance $\sigma^2$ that have been added together to give $S_n$ and where 
           $\Phi(z)$ is the cumulative probability distribution function for the standard normal distribution with expectation 0 and variance 1. 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What can we use to understand if the result from one experiment affects the outcome of a second, different experiment? </CALL>
        <RESPONSE>
           To understand if the result from one experiment, (capital) $X$, affects the outcome of a second, different experiment, (capital) $Y$ we use the 
           conditional probability.  The conditional probability that $X=3$ given $Y=2$ is equal to the probability that $X=3$ AND $Y=2$ divided by the 
           probability that $Y=2$.  In other words:
           $$
             P(X=3|Y=2) = \frac{ P(X=3 \wedge Y=2) }{ P(Y=2) }
           $$ 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What does Bayes theorem state? </CALL>
        <RESPONSE>
           Bayes theorem states that $P(X=x|Y=y)P(Y=y) = P(Y=y|X=x)P(X=x)$
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> If $X=2$ whenever $Y=4$ what can we say about the events $X=2$ and $Y=4$? </CALL>
        <RESPONSE>
             If $X=2$ whenever $Y=4$ then the events $X=2$ and $Y=4$ are concurrent.  These two events always happen at the same time and the conditional 
             probablity $P(X=2|Y=4)$ is equal to one.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> If $X$ is never equal to 2 whenever $Y=4$ what can we say about the events $X=2$ and $Y=4$? </CALL>
        <RESPONSE>
           If $X$ is never equal to 2 whenever $Y=4$ then the events $X=2$ and $Y=4$ are mutually exclusive.  $Y$'s equalling 4 somehow prevents $X$ from equalling two 
           and the conditional probability $P(X=2|Y=4)$ is equal to zero.  
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> 
          If the value the random variable $X$ takes has no effect on the value on the value the random variable $Y$ takes what can we say about the 
          random variables $X$ and $Y$ 
        </CALL>
        <RESPONSE>
          If the value the random variable $X$ takes has no effect on the value on the value the random variable $Y$ the two random variables are said to 
          be indepdent.  For all possible values of $x$ and $y$ the conditional probability $P(X=x|Y=y)=P(X=x)$ and the conditional probability $P(Y=y|X=x)=P(Y=y)$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> Can two events be both independent and mutually exclusive? </CALL>
        <RESPONSE>
          Two events $X=3$ and $Y=2$ cannot be independent and mutually exclusive as indepdences implies that the conditional probability $P(X=3|Y=2)=P(X=3)$, while
          mutual exclusivity implies that the conditional probability $P(X=3|Y=2)=0$.  We can conclude from these two equations that $P(X=3)=0$ and hence that the 
          event $X=3$ is impossible.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is a Bernoulli random variable? </CALL>
        <RESPONSE>
          A bernoulli random variable, $X$, is a discrete random variable that is used to model an experiment with two outcomes success and failure.  
          For this variable failure is given a value of 
          0 and success a value of 1.  The probability of success ($X=1$) is $p$.  The expectation of this random variable is $p$ and the variance is $p$ times $(1-p)$
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is a Binomial random variable? </CALL>
        <RESPONSE>
          A Binomial random variable is a discrete random variable that is used to model the number of successes amongst $n$ independent Bernoulli trials.  
          The probability mass function 
          for this random variable is equal to $\binom{n}{p} p^x(1-p)^{n-x}$   The expectation of this random variable is $np$, while the variance is $np(1-p)$  
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is a Geometric random variable? </CALL>
        <RESPONSE>
          A geometric random vairable is a discrete random variable that used to model the number of independent Bernoulli trials that need to be performed before 
          you get a success.  The 
          probability mass function for this random variable is equal to $(1-p)^{x-1}p$ The expectation of this random variable is $1/p$ while the variance is $(1-p)/p^2$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is an exponential random variable? </CALL>
        <RESPONSE>
          An exponential random variable is a continuous random variable that can be used to model the process of waiting for something to happen.  
          This random variable is unique in that it has no memory.  The cumulative probability distribution function for this random variable is 
          equal to $1-e^{-\lambda t}$ The expectation of this random variable is $\lambda$ and the variance is $1/\lambda^2$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is a poisson random variable? </CALL>
        <RESPONSE>
          A Poisson random variable is a discirete random variable, which can be thought of as a large $n$ limit for the binomial random variable.  
          The probability mass function for this random variable is equal to $\frac{\lambda^x}{x!}e^{-\lambda}$.  The mean and variance of this 
          random variable are both equal to $\lambda$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What does the joint probability mass function, $f_{XY}(x,y)$, measure? </CALL>
        <RESPONSE>
          The joint probability mass function $f_{XY}(x,y)$ measures the probability that the random variable $X$ is equal to $x$ and the random variable $Y$ equals
          $y$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do we calculate the covariance of a pair of random variables? </CALL>
        <RESPONSE>
          The covariance of a pair of random variables $X$ and $Y$, is calculated as $\mathbb{E}\{[X-\mathbb{E}(X)][Y-\mathbb{E}(Y)]\}$ or as
          $\mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(Y)$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is a stochastic process? </CALL>
        <RESPONSE>
          A stochastic process is a time series of random variables. 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is the simplest kind of stochastic process? </CALL>
        <RESPONSE>
          The simplest kind of stochastic process is a Markov chain.  A time series of random variables is said to have to have the Markov property if 
          the values the random variable take at future times depends only on the current value the random variable.  In other words, the values the
          random takes in the future does not depend on the values random variables took during the past.  This is a rather colloquial definition a 
          more formal definition for a Markov chain is a time series of random variables whose probability distribution functions have the following 
          property:
          $$
           P(X_{t+1}=x_{t+1} | X_0=x_0 \wedge X_1=x_1 \wedge \dots \wedge X_{t}=x_t) = P( X_{t+1}=x_{t+1} | X_{t}=x_t)
          $$ 
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What mathematical object do we use to represent the one step transition probabilities for a Markov chain? </CALL>
        <RESPONSE>
          We use a matrix to represent the one-step transition probabilities.  Element $(i,j)$ of this matrix gives the probability that the system will 
          transition from state $i$ to state $j$ in a single timestep.   
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do we calculate the probability that the system will transition from state $i$ to state $j$ over the course of $n$ timesteps? </CALL>
        <RESPONSE>
          Element $(i,j)$ of the $n$th power of the one-step transition probability matrix is equal to the probability that the system will transition from state 
          $i$ to state $j$ over the course of $n$ timesteps.  This result is known as the Chapman-Kolmogorov relation.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is the difference between a recurrent and a transient state of a Markov chain? </CALL>
        <RESPONSE>
           Any recurrent state is guaranteed to have a finite return time.  A transient state is not guaranteed to have a finite return time.  More formally
           if a state is recurrent $\sum_{n=1}^\infty (\mathbf{P}^n)_{ii} = 1$ while if a state is transient $\sum_{n=1}^\infty (\mathbf{P}^n)_{ii} &lt; 1$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How do we measure the period of a state in a Markov chain? </CALL>
        <RESPONSE>
           The period of a state is equal to the greatest common divisor of the set of possible return times to that state.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> When does a Markov chain have a limiting stationary distribution? </CALL>
        <RESPONSE>
           A Markov chain has a limiting stationary distribution when all the states in the chain are recurrent.  A markov chain with a limiting stationary 
           distribution is said to be ergodic.  This stationary distribution can be found by finding the top left eigenvector of the transition probability matrix.  
           Furthermore, a Markov chain which has only recurrent states satisfies the ergodic theorem which tells us 1 over the expected return time to a state is 
           equal to the fraction of time the system stays in that state.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What does the ergodic theorem state and when does it hold? </CALL>
        <RESPONSE>
           The ergodic theorem states that
           $$
           \lim_{n \rightarrow \infty} \frac{M_k(n)}{n} = \frac{1}{\mathbb{E}(T_k)}
           $$
           where $M_k(n)$ is the number of visits the system makes to the $k$th state in a $n$ step chain and where $\mathbb{E}(T_k)$ is the expected return time to state $k$.
           This theorem holds for Markov chains that have a finite number of recurrent states.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> What is the Kolmogorov equation? </CALL>
        <RESPONSE> 
           The Kolmogorov equation is a differential equation that is at the heart of the theory of Markov chains in continuous time.  The Kolmogorov equation 
           tells us that derivative of the transition probability matrix with respect to time is equal to the product of the jump rate matrix, $\mathbf{Q}$, 
           with the transition probability matrix, $\mathbf{P}(t)$.  In other words, $\frac{\textrm{d} P(t)}{\textrm{d}t} = \mathbf{Q} \mathbf{P}(t)$.
        </RESPONSE>
     </ITEM>
     <ITEM>
        <CALL> How is the jump rate matrix of a continuous time Markov chain defined? </CALL>
        <RESPONSE> 
           The jump rate matrix, $\mathbf{Q}$, of a continuous time Markov chain is equal to $\mathbf{P}(t)$ minus the identity over $t$ in the limit as $t$ tends to zero.
           In other words, $\mathbf{Q} = \lim_{t \rightarrow 0} \frac{\mathbf{P}(t)-\mathbf{I} }{t}$. 
        </RESPONSE>
     </ITEM>
  </LITURGY>
  <HANDBOOK>
     <ASSESSMENT>
        <DESCRIPTION> One two page report on random variables </DESCRIPTION>
        <WEIGHT> 10 </WEIGHT>
        <WHEN> 16:00 Tuesday Week 4 </WHEN>
     </ASSESSMENT>
     <ASSESSMENT>
        <DESCRIPTION> One portfolio of work done during the semester </DESCRIPTION>
        <WEIGHT> 45 </WEIGHT>
        <WHEN> 16:00 Tuesday Week 13 (1st week of second semester) </WHEN>
     </ASSESSMENT>
     <ASSESSMENT>
        <DESCRIPTION> One three hour examination in which all questions on the paper must be answered </DESCRIPTION>
        <WEIGHT> 45 </WEIGHT>
        <WHEN> April exam period </WHEN>
     </ASSESSMENT>
     <WEEK>
        <HANDIN> 
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 2 </DUE>
        </HANDIN>
        <TRY> 
            Read notes and watch all videos on random variables in content and understanding sections of website.  Use comprehension exercises to make notes on this material.    
            Attempt all blockly exercises in apply section.  Aim to at least complete the first blockly exercise before the computer class on Monday of week 2.
        </TRY>
        <TUTORIAL> No tutorial this week.  Ensure you know which tutorial you will attend next week. </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN> 
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 3 </DUE>
        </HANDIN>        
        <TRY> 
            Continue working on blockly exercises on random variables in apply section.  Try to transfer what you have learnt about generating random variables and on
            calculating summary statistics and histograms from exercises in apply section to a python notebook by performing exercises on random variable in extend section.  
            Begin writing first draft of random variable project and try to have as much of this done by the Monday computer class as possible.
        </TRY>
        <TUTORIAL> Bring mulitple copies of the report that you wrote for your portfolio.  We will be doing small group discussions that start by you reading each others reports on what aspects of the module you are finding easy/difficult. </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 4 </DUE>
        </HANDIN>        
        <HANDIN>
            <ITEM> Short report on random variables </ITEM>
            <DUE>  16:00 on Tuesday of week 4 </DUE>
        </HANDIN>
        <TRY>
            Finish random variable project and try the final projects on random variables if you have time.
        </TRY>
        <TUTORIAL> 
            Bring a draft of your random variable report to the tutorial.  We will be doing small group discussions that start by you reading each others reports on 
            random variables. 
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 5 </DUE>
        </HANDIN>
        <HANDIN>
            <ITEM> Draft project on estimating $\pi$. </ITEM>
            <DUE>  Friday week 4 </DUE>
        </HANDIN>
        <TRY>
            Read notes and watch all videos on the central limit theorem in content and understanding sections of website.  Use comprehension exercises to make notes on this 
            material.  Attempt blockly programming exercises in apply section.  Transfer what you have learnt from doing these exercises to a python notebook.  Give this to 
            me for feedback so we can make a decision on what you should try next.  Remember your draft report does not have to be perfect.
        </TRY>
        <TUTORIAL> 
            You will be attempting some short problems on the central limit theorem in groups during the tutorial.  Please make sure that you can state the central limit theorem
            and that you know how to calculate a confidence limit before the tutorial.
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 6 </DUE>
        </HANDIN>
        <TRY>
            If you struggled with the blockly exercises and with transferring what you learnt from the blockly exercise to a python notebook please ensure that you have 
            solved all your problems with this material by the end of the computer class on Monday on 5th week so that you can focus on completing a good report on this
            material by the end of week 6.  If you managed to send me a draft on esimtating $\pi$ by the end of week 4 attempt some of the harder exercises on the extend 
            and final project pages.  Start work on these projects before the computer class so that you have time to ask for help. 
        </TRY>
        <TUTORIAL> 
            Please bring your random variables report and the feedback that I wrote about your random variable report.  In class you will be doing a discussion exercise with
            your peers in which you read my feedback and think about what you could do differently to make your subsequent projects better. 
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 7 </DUE>
        </HANDIN>
        <TRY>
           This is the final week during which we will be working on the central limit theorem projects.  You should thus attempt to finish off all the outstanding work that you 
           have to do on any of the projects that you tried.  If you do not manage to finish any projects then make a note on what needs to be done in order to finish your project 
           off.  I do not want to see anyone working on the problems associated with the central limit theorem during the computer class on Monday of week 7.
        </TRY>        
        <TUTORIAL>  
            You will be attempting some short problems on Bayes theorem in groups during the tutorial.  Please make sure that you can state Bayes theorem and that you can use 
            this theorem to calculate conditional probabilities correctly.
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 8 </DUE>
        </HANDIN>
        <HANDIN>
            <ITEM> Draft project on either ehrenfest urns or gamblers ruin </ITEM>
            <DUE>  Friday week 7 </DUE>
        </HANDIN>
        <TRY>
            Read notes and watch all videos on Markov chains in discrete time in content and understanding sections of website.  Use comprehension exercises to make notes on this
            material.  Attempt blockly programming exercises on the Markov chains in discrete time in the apply section.  Transfer what you have learnt from doing these exercises 
            to a python notebook.  Give this to me for feedback so we can make a decision on what you should try next.  Remember your draft report does not have to be perfect.
        </TRY>        
        <TUTORIAL> 
            You will be attempting some short problems on Markov chains in discrete time during the tutorial.  Please make sure that you can state the Markov property, use
            the Chapman-Komogorov relation and determine whether states in Markov chains are transient or recurrent before the tutorial.
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 9 </DUE>
        </HANDIN>
        <TRY>
            If you struggled with the blockly exercises and with transferring what you learnt from the blockly exercise to a python notebook please ensure that you have
            solved all your problems with this material by the end of the computer class on Monday on 8th week so that you can focus on completing a good report on this
            material by the end of week 9.  If you managed to send me a draft on gamblers ruin or the ehrenfest urns by the end of week 7 attempt some of the harder exercises 
            on the extend and final project pages.  Start work on these projects before the computer class so that you have time to ask for help.
        </TRY>        
        <TUTORIAL> 
           You will be attempting some short problems on Markov chains in discrete time during the tutorial.  Please make sure that you can state the Markov property, use 
           the Chapman-Komogorov relation, determine whether states in Markov chains are transient or recurrent, calculate stationary distributions for Markov chains and 
           hitting times and hitting probabilities.  To do the last two of these things you will need to know how to use Gaussian elimination and how to invert matrices.
           You have been shown in other modules how to multiply and invert matrices and how to use Gaussian elimination.  If you need to revise this material do so.  
           I will not be going through it again. 
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 10 </DUE>
        </HANDIN>
        <TRY>
           This is the final week during which we will be working on the Markov chain in discrete time projects.  You should thus attempt to finish off all the outstanding work 
           that you have to do on any of the projects that you tried.  If you do not manage to finish any projects then make a note on what needs to be done in order to finish 
           your project off.  I do not want to see anyone working on the problems associated with Markov chains in discrete time during the computer class on Monday of week 10.
        </TRY>        
        <TUTORIAL> 
           You will be attempting some problems on Gamblers ruin and the Ehrenfest urns.  You should thus have familiarised yourself with these problems by performing the 
           associated programming exercises in the extend section of the section of the website on Markov chains in discrete time. 
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 11 </DUE>
        </HANDIN>
        <HANDIN>
            <ITEM> Draft project on queues </ITEM>
            <DUE>  Friday week 7 </DUE>
        </HANDIN>
        <TRY>
            Read notes and watch all videos on Markov chains in continuous time in content and understanding sections of website.  Use comprehension exercises to make notes on this
            material.  Attempt blockly programming exercises on Markov chains in continuous time from the apply section.  Transfer what you have learnt from doing these exercises
            to a python notebook.  Give this to me for feedback so we can make a decision on what you should try next.  Remember your draft report does not have to be perfect.
        </TRY>        
        <TUTORIAL> 
            You will be attempting some short problems on the Poisson process during the tutorial.  You will do the questions under exam conditions but you will be allowed to use 
            your notes.  To do these problems you will need to be able to solve varaible separable first order differential equations and to solve first order differential 
            equations using an integrating factor.  Both of these techiniques are covered in the first year and I will not be going over this material again.  Therefore, if you 
            need to revise this material please do so.  Furthermore, notice that the required mathematics is covered in the videos on the Poisson process.
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Half page report for portfolio </ITEM>
            <DUE>  16:00 on Tuesday of week 12 </DUE>
        </HANDIN>
        <TRY>
           If you struggled with the blockly exercises and with transferring what you learnt from the blockly exercise to a python notebook please ensure that you have
           solved all your problems with this material by the end of the computer class on Monday on 11th week so that you can focus on completing a good report on this
           material by the end of week 12.  If you managed to send me a draft on queues by the end of week 10 attempt some of the harder exercises
           on the extend and final project pages.  Start work on these projects before the computer class so that you have time to ask for help.
        </TRY>        
        <TUTORIAL> 
            Bring a draft of your best portfolio report to the tutorial.  We will be doing small group discussions that start by you reading each others reports.
        </TUTORIAL>
     </WEEK>
     <WEEK>
        <HANDIN>
            <ITEM> Two best reports for portfolio - please hand in as a single document </ITEM>
            <DUE>  16:00 on Tuesday of week 13 (i.e. first week of second semester) </DUE>
        </HANDIN>
        <TRY>
            This is the final week of the semester.  You should thus use the computer class to ensure that you have the information that you need in order to complete your three
            portfolio reports during the break. 
        </TRY>        
        <TUTORIAL> 
           Drop in session for you to ask for advice about what to hand in for your portfolio.
        </TUTORIAL>
     </WEEK>
  </HANDBOOK>
  <PORTFOLIO>
     <DESCRIPTION>
        One of the components of the assessment for this module is a portfolio of work that you must produce over the course of the semester.  This portfolio counts for 45 
        percent of your final module mark.  It should contain:

        \begin{itemize}
        \item[(A)] 10 reports describing what you have worked on each week.  These reports are due by 16:00 on Tuesday in weeks 2 through 12 of the semester.  
            See the self study section of the markscheme below. 
        
        \item[(B)] Three attempts at the projects detailed in either the extend or final project sections of the module pages.  You should attempt as many of these projects 
            as you can over the course of the semester and hand in the three that you felt were your best attempts by 16:00 on the Tuesday of week 13.  You should not hand in 
            the project on random variables that you produced in week 4 for this assessment to be reassessed as this project is already assessed as part of a different module 
            component.  On my website you will notice that each project has been ascribed a level of difficulty that ranges from 1 to 4.  As explained below the level acts as 
            a guide on the maximum mark that you can get by handing in that particular project.  If you choose to submit level 1 projects for instance you can score a maximum 
            of 24/40.  To be clear, however, this does not mean you should not attempt the easier projects.  You should in fact ALWAYS start with an attempt on the level 1 
            projects before moving on to the harder projects as poor attempts on the harder projects will most likely fail.  In short, I would rather see good attempts at the 
            easier projects than bad attempts at the harder projects.     
        \end{itemize}

        Notice that tutorials and the computer classes are compulsory and that you will be awarded a mark of zero for the portfolio project if you do not attend 70 percent 
        of the tutorials and computer classes.  In addition, notice that your portfolio will be awarded a mark of zero if it does not contain all of the components detailed 
        above (10 weekly reports and 3 projects).
     </DESCRIPTION>
     <COMPONENT>
        <TITLE> Self study </TITLE>
        <DESCRIPTION>
            The first component of the assessment is based on how you have studied for the module.  You must hand in a report that is at least half a page in length every week in which you detail what, when and how you 
            intended to study during the week and what you actually achieved during the week.  You may choose to detail what resources you have used and what parts of the material you found 
            easy and what you found difficult.  You might also want to talk about any conversatiosn you had the lecturer/teaching assistants.  You should also explain what resources you studied 
            from and what resources were particularly useful.  Lastly, you should demonstrate that you have thought about what you did this week and how you might study more effectively in the 
            future.
        </DESCRIPTION>
        <RANGE> 
           <CLASSIFICATION> Excellent </CLASSIFICATION>
           <MARKS> 4-5 </MARKS>
           <QUALITY> 
              The student outlines a clear plan detailing what and when they will study each week.  There is evidence that the student thinks about 
              how well their plan has worked at the end of each week and evidence that they have though how to refine their plans in subsequent weeks.
              They reflect well on their previous work and feedback and learn by evaluating both positive and negatives.  
           </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Good work </CLASSIFICATION>
           <MARKS> 2 </MARKS>
           <QUALITY> 
               The student outlines a clear plan detailing what and when they will study each week but evidence that they have though about how well this plan is working is absent.
               The student reflects on previous work and feedback and evaluates both positive and negatives.  There is, however, little evidence that they are refining how they are 
               studying as the semester progresses, however.
           </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Adequate </CLASSIFICATION>
           <MARKS> 1 </MARKS>
           <QUALITY>
               Some evidence that the student plans what items to study each week.  There is some evidence to support reflection although there could be more reference 
               to previous work.  A discussion that has a no balance between discussing of what has worked and what has not worked is absent. 
           </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Fail </CLASSIFICATION>
           <MARKS> 0 </MARKS>
           <QUALITY> 
               No evidence of regular self study.  No evidence of reflection.  Less than 75 \% attendance at tutorials and computer lab classes
           </QUALITY>
        </RANGE>
     </COMPONENT>
     <COMPONENT>
        <TITLE> Mark capping for projects </TITLE>
        <DESCRIPTION>
            As discussed above each project has an associated level of difficulty and the marks that you will receive will be capped based on the level of difficulty of the 
            projects you attempt.  To be clear, the expectation is that you attempt A LOT of the projects and that you decide what you can and cannot do yourself.  In other
            words, attempt the projects at levels 1, 2 and 3 before attempting the projects at level 4.  Please do not feel pressured to attempt projects that you do not 
            understand in order to get a higher mark.  If you do so you will most likely get a very poor mark as I would rather see the easier projects done to a high standard
            than the harder projects completed to a very low standard.  Also note that I would like to see you attempt projects from all the chapters of the module.  Please do 
            not submit level 1, level 2 and level 3 projects that are all on the central limit theorem.  If you do this your portfolio will be given a very low mark. 
        </DESCRIPTION>
        <RANGE>
           <CLASSIFICATION> Level 4 (high first) </CLASSIFICATION>
           <MARKS> Max 40 </MARKS>
           <QUALITY> This will be the projects that appear on the final project page.  To score marks this high you are expected to find a problem to solve yourself and to develop a strategy to solve the problem you thought of using the material you have learnt.  You can also design your own problem without using the prompts on the final project pages but please discuss what you would like to do with me first. </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Level 3 (low first) </CLASSIFICATION>
           <MARKS> Max 32 </MARKS>
           <QUALITY> These projects appear on the extend pages and are marked level 3.  These projects ask you to use material that you will learn by doing the blockly exercise together with material that you have learnt about in other parts of the maths course to solve a problem that has some marked difference from the one you encountered in the blockly exercises.  You will need to use many of the ideas that were introduced in the blockly exercise to solve the new problem, however. </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Level 2 (2.1) </CLASSIFICATION>
           <MARKS> Max 28 </MARKS>
           <QUALITY> These projects appear on the extend pages and are marked level 2.  These problems will involve the material that you have learnt about by doing the blockly exercises to solve a problem that is similar to the problem you worked on in the blockly exercise. </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Level 1 (2.2) </CLASSIFICATION>
           <MARKS> Max 24 </MARKS>
           <QUALITY> These projects appear on the extend pages and are marked level 1.  Essentially what you are asked to do for these projects is to transfer what you learnt to do by performing the blockly exercise to a python notebook. </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Level 0 (3) </CLASSIFICATION>
           <MARKS> Max 16 </MARKS>
           <QUALITY> These projects appear on the extend pages and are marked level 0.  These projects involve no programming and involve you simply finding a mathematical derivation that is in the notes and reproducing it in your own words. </QUALITY>
        </RANGE>
     </COMPONENT>
    <COMPONENT>
        <TITLE> Final mark </TITLE>
        <DESCRIPTION>
           When marking a project I will award the first 16 marks if your project does not contain grevious errors.  To be clear the expectation for project work is that all 
           the mathematics in your report should be correct.  Your report will then be given a mark out of 8 using the scale below.  This mark will then be multiplied by a 1 
           if the project is level 1, 1.5 if the project is level 2, 2 if the project is level 3 and 3 if the project is level 4.  If the project is level 0 you will get a maximum
           of 16 marks.

           Your final mark portfolio mark is the arithmetic mean of the marks that you obtain for the three projects.  Remember, however, that you you must submit three projects 
           from three different chapters of the module and that penalties will be applied if you submit more than one project on the same chapter.  For example if you submit a 
           level one and level four project on the same chapter the level four project will be marked as if it is a level 1 project. 
        </DESCRIPTION>
        <RANGE>
           <CLASSIFICATION> Outstanding </CLASSIFICATION>
           <MARKS> 7-8 </MARKS>
           <QUALITY>
              A piece of software that solves the problem is provided and error bars for all averages are quoted.  The explanation as to what work has been done is 
              clear, concise and transparent.  
            </QUALITY>
        </RANGE>
        <RANGE>
           <CLASSIFICATION> Excellent </CLASSIFICATION>
           <MARKS> 5-6 </MARKS>
           <QUALITY>
              A piece of software that solves the problem is provided and in addition error bars are quoted for all the averages that have been computed.  What has been 
              done is explained reasonably clearly although it lacks precision in places.
            </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Good work </CLASSIFICATION>
           <MARKS> 3-4 </MARKS>
           <QUALITY> 
              A piece of software that solves the problem is provided together with a partial explaination of how the code works that lacks precision in places.  Importantly, 
              the report contains no careless presentation errors although error bars on some of the averages that have been computed might be absent.
           </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Adequate </CLASSIFICATION>
           <MARKS> 1-2 </MARKS>
           <QUALITY> 
              The student demonstrates an incomplete understanding of the problem.  A piece of software that only partially works is provided. There is little to no 
              explanation as to how the code operates.  The report contains careless presentation errors such as unlabelled axis in graphs or undefined symbols in equations. 
           </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Pass </CLASSIFICATION>
           <MARKS> 0 </MARKS>
           <QUALITY>
              To be clear a pass here means that you are awarded 16 marks for your project only.  Anything better than a pass is awarded these 16 marks plus the mark for that 
              level of work (see above) multiplied by the appropriate scaling factor for the project difficulty.  A pass mark will be awarded unless there are grevious mistakes
              in the work that you produce.  This is the maximum mark you can obtain by doing a level 0 project that involves no programming.   
           </QUALITY>
        </RANGE>
       <RANGE>
           <CLASSIFICATION> Fail </CLASSIFICATION>
           <MARKS> 0 </MARKS>
           <QUALITY>
              Students attends less than 70 percent of the tutorials and computer classes.  Student fails to hand in all the work that is required for the portfolio.
           </QUALITY>
        </RANGE>
     </COMPONENT>
  </PORTFOLIO>
  <CHAPTER>
     <TITLE> Random variables </TITLE>
     <INTRO>
        <DESCRIPTION> 
           The first project in the course is all about revisiting the material on random variables and probability theory that you learnt in the level one course.  During this part of the course you 
           will learn about uniform, bernoulli, binomial, poisson, geometric and normal random variables.  You will revise important concepts in probability theory and statistics such as expectation,
           variance, independence, cumulative probability distribution functions, probability density functions and probability mass fuctions.  You will also be introduced to the moment generating 
           function.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to explain how the cumulative probability distribution function and the probabiltiy mass/density function are related. </LI>
              <LI> You should be able to write out the probability mass functions for the bernoulli, binomial, poisson and geometric rando variables.  You should be able to write out the probability density functions for the uniform and normal random variables. </LI>
              <LI> You should be able to calculate expectations and variances directly, using the moment generating function and by using the conditional expectation theorem. </LI>
              <LI> You should be able to write programs to generate uniform, bernoulli, binomial, poisson, geometric and normal random variables. </LI>
           </UL>
        </AIMS> 
     </INTRO>
     <PROJECT>
        <TITLE> Investigating other random variables </TITLE>
        <DESCRIPTION>
           Performing the exercises in the apply and extend parts of this project will teach you how to generate uniform, bernoulli, binomial, poisson, geometric, exponential and normal random variables.
           You will learn how to derive expressions for the expectations and variances of these different types of random variables from the random variables parameters.  Furthermore, you 
           will learn about the law of large numbers and how we can estimate expectations and probability distribution functions by repeatedly generating random variables from a particular 
           distribution.  Some suggestions as to how to take your research in these ideas a little further are given below.  You may also want to discuss what you plan to research further with your lecturer.

           <UL>
              <LI> As part of your project on random variables you wrote a program to estimate the probability mass/density function for a particular random variable that worked by generating a large number of identically distributed random variables.  Now write a program to estimate the cumulative probability distribution function for the same kind of random variable you wrote your project on. </LI> 
              <LI> Suppose that $X$ is a geometric random variable with $p=0.5$.  Now suppose that we generate a random variable $Z$ that is a function of $X$ using $Z = 2^X$.  Write a python notebook that generates multiple instances of this random variable $\{ Z_i \}$.  Draw a graph that shows how the sample mean, $\mu_n = \frac{1}{N} \sum_{i=1}^n Z_i$, changes as the number of variables it is calculated from increases.  Discuss the behaviour of this sample mean and compare it to the behaviour that you observed for the other random variables you have investigated.  Derive an expression for the expression for the expectation of this random variable and use this expression to explain why the sample mean for this random variable behaves in the way you observe. </LI> 
              <LI> Write a program that generates random variables from a Cauchy distribution.  Generate a large number of identically distributed Cauchy random variables and use this data to estimate the probability density function for your random variable.  </LI>
              <LI> Discuss how Student's-t-distribution arises from sampling and how this distribution differs from the standard normal distribution.  You should write a program that generates random variable from Student's-t-distribution and make sure that you plot the a graph of showing how the shape of the $t$ distribution changes as the number of degrees of freedom is increased. </LI>
           </UL>
        </DESCRIPTION>
     </PROJECT>
     <TOPIC> RANDOM_VARIABLES </TOPIC>
     <TOPIC> BERNOULI_RANDOM_VARIABLE </TOPIC>
     <TOPIC> BINOMIAL_RANDOM_VARIABLE </TOPIC>
     <TOPIC> GEOMETRIC_RANDOM_VARIABLE </TOPIC>
     <TOPIC> POISSON_RANDOM_VARIABLE </TOPIC>
     <TOPIC> UNIFORM_RANDOM_VARIABLE </TOPIC>
     <TOPIC> NORMAL_RANDOM_VARIABLE </TOPIC>
     <TOPIC> EXPECTATION </TOPIC>
     <TOPIC> VARIANCE </TOPIC>
     <TOPIC> MOMENT_GENERATING_FUNCTION </TOPIC>
     <TOPIC> LAW_OF_LARGE_NUMBERS </TOPIC>
  </CHAPTER>
  <CHAPTER>
     <TITLE> The central limit theorem </TITLE>
     <INTRO>
        <DESCRIPTION>
           The second project in the course is all about the central limit theorem, which is arguably the central theorem in statistics.  Once again you learnt about this theorem in level one but this 
           material is difficult so it bears repeating.  The central idea idea that we are trying to get at with this part of the course concerns using probability theory to develop a numerical measure 
           for the degree of confidence that we have in a particular (quantitative) statement.  The simple version of this idea is that if we have two measurements of some quantity that are very similar 
           we are more likely to believe that each of the individual measurements represent something close to the truth.  We are mathematicians though so we would like to develop a more quantitative version 
           of this intuition.  This is what the central limit theorem allows us to do.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to explain the difference between systematic and random error. </LI> 
              <LI> You should be able to state the central limit theorem and define all the terms in this theorem correctly. </LI>
              <LI> You should be able to calculate confidence limits that give a measure of the random error in the sample mean calculated from a set of indepdendent random variables. </LI>
           </UL>
        </AIMS>
     </INTRO>
     <PROJECT>
        <TITLE> Monte Carlo Integration </TITLE>
        <DESCRIPTION>
           The method that we have been focussing on using during the blockly and python exercises this week is known as Monte Carlo integration or sometimes importance sampling.
           As I eluded to in the exercises this technique is used a wide variety of different fields of mathematics to calculate integrals.  In all the exercises, however, we have 
           only ever used this method to calculate the expectation of a Bernoulli random variable.  Try to write a python notebook in which you estimate the value of some ofther  
           integral by using Monte Carlo sampling.  This integral might be the expectation/variance of some particularly complicated random variable or it might be some integral 
           that is easy to compute analytically.  To do this you will need to perform some research online on this particular method.  Lastly, note that for whatever integral you 
           choose to perform ensure that you must provide suitable error bars on the numerical estimate that you obtain by Monte Carlo sampling.  
        </DESCRIPTION>
     </PROJECT>
     <TOPIC> CONDITIONAL_PROBABILITY </TOPIC>
     <TOPIC> INDEPENDENT_RANDOM_VARIABLES </TOPIC>
     <TOPIC> JOINT_PROBABILITY_DISTRIBUTION </TOPIC> 
     <TOPIC> BAYES_THEOREM </TOPIC>
     <TOPIC> CONDITIONAL_EXPECTATION </TOPIC>
     <TOPIC> CENTRAL_LIMIT_THEOREM </TOPIC>
  </CHAPTER>
  <CHAPTER>
     <TITLE> Markov chains in discrete time </TITLE>
     <INTRO>
        <DESCRIPTION>
           In this third project we introduce the Markov property and thus begin our study of random, time-dependent processes.  In this part of the course we assume that we are monitoring our 
           random process at particular points in time rather than assuming we are monitoring the random process continuously.  Furthermore, we assume that the random variable whose value we 
           are monitoring in time can only take integer values.  To describe these processes we introduce the notion of a transition graph and a transition matrix.  You will learn how to write programs
           to simulate Markov chains and will learn how quantitative predictions can be made for these random processes by examining the limiting behavior of the chains.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to state what it means when we say that a time series of random variables has the Markov property </LI>
              <LI> You should be able to interpret transition graphs and transition probability matrices and you should also be able to use the Chapman-Kolmogorov relation to calculate the $n$-step transition probability matrix from the 1-step transition probability matrix. </LI>
              <LI> You should be able to discuss the limiting behavior of Markov chains.  This means you should be able to calculate limiting stationary distributions, hitting times and hitting probabilities. </LI>
              <LI> You should be able to write a computer program to simulate a random walk in one dimension. </LI>
           </UL>
        </AIMS>
     </INTRO>
     <PROJECT>
       <TITLE> Metropolis sampling </TITLE>
       <DESCRIPTION>
         A number of important techniques for calculating integrals are based on the Metropolis sampling algorithm.  Research how this algorithm works and write a program
         to calculate an integral using this technique.  Remember to quote error bars on any estimate that is extracted by calculating a sample mean.  Notice that 
         I will award a higher mark if you explain why the integral you have chosen to perform is useful to calculate.  With this in mind some fields where the Metropolis
         algorithm is used that you might choose to investigate include statistical mechanics (physics) and Bayesian statistics.
       </DESCRIPTION>
     </PROJECT>
     <TOPIC> MARKOV_PROPERTY </TOPIC>
     <TOPIC> TRANSITION_MATRIX_OF_MARKOV_CHAIN </TOPIC>
     <TOPIC> CHAPMAN_KOLMOGOROV_RELATION </TOPIC>
     <TOPIC> GAMBLERS_RUIN </TOPIC>
     <TOPIC> TRANSIENT_RECURRENT_STATES </TOPIC>
     <TOPIC> STATIONARY_DIST_MARKOV </TOPIC>
     <TOPIC> HITTING_PROBABILITIES </TOPIC>
  </CHAPTER>
  <CHAPTER> 
     <TITLE> Markov chains in continuous time </TITLE>
     <INTRO>
        <DESCRIPTION>
           The final part of the course takes what you have learnt about discrete time Markov chains and extends it so that it also works in continuous time.  Doing so ensures that we can model processes
           where there are discrete states and where the times between transitions between these states are random.  We can thus use the theory of Markov chains to model processes such as queues and the 
           progression of diseases.  A discussion of Markov chains in continous time also allows us to move beyond the Markovian assumption and to thus introduce more complex time-dependent random processes.
        </DESCRIPTION>
        <AIMS>
           <UL>
              <LI> You should be able to write out and solve the Kolmogorov forward equation. </LI>
              <LI> You should be able to derive the equations of the Poisson process and you should also be able to write programs to simulate poisson processes. </LI>
              <LI> You should be able to work with Markov models that describe queues. This includes being able to  write programs to simulate queues. </LI>
              <LI> You should be able how models of random processes that relax the assumption of Markovianity can be developed. </LI>
           </UL>
        </AIMS>
     </INTRO>
     <PROJECT>
       <TITLE> Field tests for Glaucoma </TITLE>
       <DESCRIPTION>
          Glaucoma is a disease of the eyes that affects old people.  One of the symptoms of this disease is a loss of periferal vision and a narrowing of the patients 
          field of vision.  Patients who have Glaucoma thus undergo regular visual field tests in order to monitor the progress of the disease.  When a person undergoes 
          a field test their head is placed in a machine that resembles a urinal with one eye blindfolded.  The patient stares at an led in the center
          of the machine, while short and sharp burst appear at various points in the remainder of the machine.  The patient must then push a button whenever s/he sees one of these
          bursts of light.

          <UL>
            <LI> Write a program that could be used to control where and when the points of light are generated inside a machine for performing field tests and how bright they are.  Explain how your program addresses the fact that people are primed to recognize regular repeating patterns in the intervals between events when there are repeated stimuli.  This is a problem for field tests as people's subconciouses might lead them to see lights that simply are not there if the timing between each light being generated is too regular. </LI>
            <LI> Write a program that is able to simulate the patients response (pressing the button) in repsonse to each of the light pulses generated by your program.  Discuss what experiments you would need to do on patients in order to determine how to set the parameters in your algorithm for generating light pulses. </LI>  
          </UL> 
       </DESCRIPTION>
     </PROJECT>
     <TOPIC> CONTINUOUS_TIME_MARKOV_CHAIN </TOPIC>
     <TOPIC> EXPONENTIAL_RANDOM_VARIABLE </TOPIC>
     <TOPIC> POISSON_PROCESS </TOPIC>
     <TOPIC> MM1_QUEUE </TOPIC>
     <TOPIC> INHOMOGENEOUS_POISSON_PROCESS </TOPIC>
     <TOPIC> COMPOUND_POISSON_PROCESS </TOPIC>
  </CHAPTER>
</PAGE>
